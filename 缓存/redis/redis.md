# 一 杂项讲解
①单进程模型来处理客户端的请求，对读写等事件的响应是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率。  
> Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，
它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。

②select命令切换数据库  
③dbSize查看当前数据库的key的数量  
④flushDb：清空当前库  
⑤flushAll：通杀全部库  
⑥所有库密码一样  

# 二 持久化
## 2.1 RDB
【概念】  
在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照。恢复时是将快照文件移动到安装目录后启动服务器即可，
它会读取到内存中。RDB保存的是dump.rdb文件。  
【实现原理】  
redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要
比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。  
> fork的作用是复制一个与当前进程一样的进程，新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，
并作为原进程的子进程。  

【如何触发RDB快照】  
①配置文件中默认的快照配置  
②save：只管保存，其他不管，全部阻塞  
  bgSave：redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastSave命令获取最后一次成功执行快照的时间  
③执行flushAll命令，也会产生dump.rdb文件，但里面是空的，无意义  

【优势】  
①适合大规模的数据恢复  
②对数据完整性和一致性要求不高  

【劣势】  
①在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改  
②fork的时候，内存中的数据被克隆了一份，大至2倍的膨胀性需要考虑

## 2.2 AOF
【概念】  
以日志的形式来记录每个写操作，将redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新
构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。AOF保存的是appendOnly.aof文件  
【恢复】  
先修改appendOnly no为yes，将有数据的aof文件复制一份保存到对应目录，若文件异常，则启动会报错，需要先用redis-check-aof --fix进行修复，然后重启redis即可
【rewrite】  
AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，
只保留可以恢复数据的最小指令集。可以使用命令bgrewriteaof。  
AOF文件持续增大而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条set语句。重写
aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。  
redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。  
【优势】  
①每修改同步：appendfsync always，同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好  
②每秒同步：appendfsync everysec，异步操作，每秒记录，如果一秒内宕机，有数据丢失  
③不同步：appendfsync no，从不同步  
【劣势】  
①相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb  
②aof运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同  

## 2.3 持久化对比
①RDB持久化方式能够在指定的时间间隔对你的数据进行快照存储  
②AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。
redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。  
③当同时开启两种持久化方式时，在这种情况下，redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下，AOF文件保存的数据集要比RDB文件
保存的数据集要完整。RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件，但是也不要只使用AOF文件，因为RDB更适合用于备份数据库，AOF文件
在不断变化不好备份，而且存在潜在的BUG。  
  
## 2.4 持久化总结
因为RDB文件只用作后备用途，建议只在slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。  
如果enable aof，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本简单只load自己的aof文件就可以了。代价是带来了持续的IO，而且
AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，
AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。  
如果不enable aof，仅靠master-slave replication实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果master/slave
同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个master/slave中的RDB文件，载入较新的那个。

# 三 redis的复制
【概念】  
也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，master以写为主，slave以读为主。  
可以实现读写分离和容灾恢复  
【操作步骤】  
①配从库不配主库  
②从库配置：slaveof 主库IP 主库端口。每次与master断开之后，都需要重新连接，除非你配置进redis.conf文件  
③需要拷贝多个redis.conf文件，并且开启daemonize yes，然后指定pid文件名字，指定端口号，修改log文件名字，修改dump.rdb文件名字  
```
info replication
```
【常用方案】  
①一主二仆：一个master两个slave
问题思考：  
切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制？比如从k4进来后，那么之前的123是否也可以复制？  
从机是否可以写？set可否？  
主机shutdown后情况如何？从机是上位还是原地待命？  
主机又回来了后，主机新增记录，从机还能否顺利复制？  
其中一台从机down掉后，依照原有它能跟上大部队吗？  
②薪火相传：上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master，
可以有效减轻master的写压力。  
中途变更转向：会清除之前的数据，重新建立拷贝最新的  
③salveof no one：使当前数据库停止与其他数据库的同步，转成主数据库  
【复制原理】  
①slave启动成功连接到master后会发送一个sync命令  
②master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，
以完成一次完全同步。  
③全量复制是slave服务在接收到数据库文件数据后，将其存盘并加载到内存中  
增量复制是master继续将新的所有收集到的修改命令依次传给slave，完成同步  
但是只要是重新连接master，一次完全同步（全量复制）将被自动执行
【复制缺陷】  
由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，
当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。
## 哨兵模式
能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换位主库。  
【实现步骤】  
①新建sentinel.conf文件，名字不能出错  
```sentinel monitor 被监控数据库名字 127.0.0.1 6379 1（最后的数字1，表示主机挂掉后slave投票看让谁接替成为主机，得票数多少后成为主机）```  
②启动哨兵  
redis-sentinel ...sentinel.conf
**问题：如果之前的master重启回来，不会造成双master冲突，之前的master会变成slave加入集群中**

# 使用场景


# Lua脚本
①`EVAL`执行一段lua脚本，每次都需要将完整的lua脚本传递给redis服务器  
②`SCRIPT LOAD`将一段lua脚本缓存到redis中并返回一个tag串，并不会执行  
③`EVAL SHA`执行一个脚本，不过传入参数是②中返回的tag，节省网络带宽  
④`SCRIPT EXISTS`判断②返回的tag串是否存在服务器中  
⑤`SCRIPT FLUSH`清除服务器上的所有缓存的脚本  
⑥`SCRIPT KILL`杀死正在运行的脚本  
⑦`SCRIPT DEBUG`设置调试模式，可设置同步、异步、关闭，同步会阻塞所有请求  



https://www.jb51.net/article/155720.html




