-------------------------
下一次完善内容：  
①配置文件注释  
②redis事务相关、发布订阅、复制、以及客户端jedis的使用
-------------------------

# 使用场景（需不断更新）
string：  
点赞数量可以用incr key来记录。商品编号、订单编号也可以采用incr命令生成。微信文章的阅读数量也可以用这个命令来记录，只要点进去的过的都加1。

hash：可以用来存储对象，因为hash类型的结构(key,field,value)与对象(对象id,属性，值)的结构是类似的（比如票单通系统的租户信息的缓存...）。

list：用```lpush```来装载用户订阅的文章的id，``` lpush 用户id 文章id 文章id ```，之后要查看某人自己订阅的全部文章，可以用```lrange 用户id 0 10 ```，查看用户订阅的文章的前10条。
除此之外，可以将每隔一段时间计算一次的排行榜存储在list类型中，如京东每日的手机销量排行榜，音乐金曲排行榜。

TODO: 啥意思

> 当然，并不是所有的排行榜都能用list类型实现，只有定时计算的排行榜才适合使用list类型来存储。list类型不支持实时计算的排行榜。
对于排行榜和最新列表两种应用场景，list类型能做到的sorted set类型都能做到，list类型做不到的sorted set类型也能做到，
那为什么还要使用list类型去实现排行榜或最新列表呢，直接用sorted set类型不是更好吗？原因是sorted set类型占用的内存容量是list类型的数倍之多
（之后会在容量章节详细介绍），对于列表数量不多的情况，可以用sorted set类型来实现，比如上文中举例的打擂金曲排行榜，每天全国只有一份，
两种数据类型的内存容量差距可以忽略不计，但是如果要实现某首歌曲的翻唱作品地区排行榜，数百万的歌曲，300多个地区，会产生数量庞大的榜单，
或者数量更加庞大的朋友圈点赞列表，就需要慎重地考虑容量的问题了。

set：在微信抽奖小程序时，如果某用户立即参与抽奖，```sadd key 用户id```，显示已经有多少人参与了抽奖，用```scard key```，抽奖的时候，从set中任意选取N个中奖人，  
```srandmember key 2``` 随机抽奖2个人，元素不删除。```spop key 3```随机抽奖3个人，元素会删除。  
在朋友圈点赞时，记录新增点赞的功能时，可以用```sadd 发布的消息的id 点赞用户id1 点赞用户id2```  
取消点赞时，可以使用```srem 发布的消息的id 点赞用户id```  
展现所有点赞过的用户，```smembers 发布的消息的id```，在这里罗列的就是所有点赞过的用户的头像  
点赞用户数统计，就是常见的点赞红色数字，```scard 发布的消息的id```  
判断某个朋友是否对楼主点赞过，```sismember 用户id 发布的消息的id```  
在设计微博好友的社交关系时，共同关注的人可以取集合的交集，```sinter key1 key2```  
在推荐好友的时候，可以取差集运算，如```sdiff key1 key2```，此时得到的结果是key1中存在，key2中不存在，因此可以将这个结果推荐给key2，作为可能认识的人。  

```zset``` ：根据商品销售量对商品进行排行显示，定义商品销售排行榜，key为```goods:sellsort```，分数为商品销售数量  
商品编号为1001的销量是9，商品编号1002的销量是15，```zadd goods:sellsort 9 1001 15 1002```  
有一个客户又买了2件商品1001，商品编号 1001 销量加2，```zincrby goods:sellsort 2 1001```  
求商品销量前10名，```zrevrange goods:sellsort 0 10 withscores（从高到低）,zrange（从低到高）```  
抖音热搜排行榜，点击视频时，点击量加1，```zincrby hotvcr:20200919 1 八佰```  
如果要展示当日排行榜前10条时，可以使用```zrevrange hotvcr:20200919 0 9 withscores```  

# 单进程理解
单进程模型来处理客户端的请求，对读写等事件的响应是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率。  
Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。

# 配置文件概述

# 持久化
## RDB
【概念】  
在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照。恢复时是将快照文件移动到安装目录后启动服务器即可，它会读取到内存中。RDB保存的是dump.rdb文件。  

【实现原理】  
redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要
比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。  
fork说明：  
fork的作用是复制一个与当前进程一样的进程，新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。  

【如何触发RDB快照】  
①save：只管保存，其他不管，全部阻塞  
②BGSave：redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastSave命令获取最后一次成功执行快照的时间  
③执行flushAll命令，也会产生dump.rdb文件，但里面是空的，无意义  

【优势】  
适合大规模的数据恢复，对数据完整性和一致性要求不高  

【劣势】  
①在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改  
②fork的时候，内存中的数据被克隆了一份，大至2倍的膨胀性需要考虑  

【常用命令】  
① config set save ""  // 动态停止RDB保存规则
② config get dir      // 获取安装目录

## AOF
【概念】  
以日志的形式来记录每个写操作，将redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新
构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。AOF保存的是appendOnly.aof文件。  

【恢复】  
先修改appendOnly no为yes，将有数据的aof文件复制一份保存到安装目录，若文件异常，则启动会报错，需要先用```redis-check-aof --fix```指令进行修复，然后重启redis即可

【rewrite】  
AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，
只保留可以恢复数据的最小指令集。可以使用命令```bgrewriteaof```。  
AOF文件持续增大而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条set语句。重写
aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。  
redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。  

【优势】  
①每修改同步```appendfsync always```，同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好  
②每秒同步```appendfsync everysec```，异步操作，每秒记录，如果一秒内宕机，有数据丢失  
③不同步```appendfsync no```，从不同步  

【劣势】  
①相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb  
②aof运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同  

## 持久化总结
①RDB持久化方式能够在指定的时间间隔对你的数据进行快照存储  
②AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。
redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。  

③当同时开启两种持久化方式时，在这种情况下，redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下，AOF文件保存的数据集要比RDB文件
保存的数据集要完整。  
RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件，但是也不要只使用AOF文件，因为RDB更适合用于备份数据库，AOF文件
在不断变化不好备份，而且存在潜在的BUG。  

### 建议
因为RDB文件只用作后备用途，建议只在slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。  
如果enable aof，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本简单只load自己的aof文件就可以了。代价是带来了持续的IO，而且
AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，
AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。  
如果不enable aof，仅靠master-slave replication实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果master/slave
同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个master/slave中的RDB文件，载入较新的那个。

# 三 redis的复制
【概念】  
也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，master以写为主，slave以读为主。  
可以实现读写分离和容灾恢复  
【操作步骤】  
①配从库不配主库  
②从库配置：slaveof 主库IP 主库端口。每次与master断开之后，都需要重新连接，除非你配置进redis.conf文件  
③需要拷贝多个redis.conf文件，并且开启daemonize yes，然后指定pid文件名字，指定端口号，修改log文件名字，修改dump.rdb文件名字  
```
info replication
```
【常用方案】  
①一主二仆：一个master两个slave
问题思考：  
切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制？比如从k4进来后，那么之前的123是否也可以复制？  
从机是否可以写？set可否？  
主机shutdown后情况如何？从机是上位还是原地待命？  
主机又回来了后，主机新增记录，从机还能否顺利复制？  
其中一台从机down掉后，依照原有它能跟上大部队吗？  
②薪火相传：上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master，
可以有效减轻master的写压力。  
中途变更转向：会清除之前的数据，重新建立拷贝最新的  
③salveof no one：使当前数据库停止与其他数据库的同步，转成主数据库  
【复制原理】  
①slave启动成功连接到master后会发送一个sync命令  
②master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，
以完成一次完全同步。  
③全量复制是slave服务在接收到数据库文件数据后，将其存盘并加载到内存中  
增量复制是master继续将新的所有收集到的修改命令依次传给slave，完成同步  
但是只要是重新连接master，一次完全同步（全量复制）将被自动执行
【复制缺陷】  
由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，
当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。
## 哨兵模式
能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换位主库。  
【实现步骤】  
①新建sentinel.conf文件，名字不能出错  
```sentinel monitor 被监控数据库名字 127.0.0.1 6379 1（最后的数字1，表示主机挂掉后slave投票看让谁接替成为主机，得票数多少后成为主机）```  
②启动哨兵  
redis-sentinel ...sentinel.conf
**问题：如果之前的master重启回来，不会造成双master冲突，之前的master会变成slave加入集群中**

# 使用场景

【分布式锁】  
第一步：  
使用redis实现分布式锁，首先需要保证加锁【①+②】和删除锁【③+④】的原子性  
①set key value NX（不存在才设置值）  
②set key value EX 100 NX（设置过期时间）  
③判断分布式锁的值与当前线程保存的值是否相等，相等才发删除该锁的命令  
④delete key  
第二步：  
保证③和④的原子性操作需要使用Lua脚本：  
String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end"
第三步：  
锁的自动续期  

【redisson】  
lock.lock()  
阻塞式等待：默认加的锁都是30S时间  
1）、锁的自动续期，如果业务超长，运行期间自动给锁续上新的30S。不用担心业务时间长，锁自动过期被删掉  
2）、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30S以后也会自动删除  
3）、只要占锁成功，就会启动一个定时任务，该定时任务的作用是重新给锁设置过期时间，新的过期时间就是看门狗的默认时间，每隔10秒，
都会将锁的过期时间重新设置成30S

lock.lock(10,TimeUnit.SECONDS)  
**10秒自动解锁，自动解锁时间一定要大于业务的执行时间**  【因为没有自动续期功能，不这样设置会导致锁的误删问题】  
注意：此方法在锁时间到了以后，不会自动续期  
1）如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时时间就是我们指定的时间  
2）如果我们未指定锁的超时时间，就使用30*1000【LockWatchDogTimeOut看门狗的默认时间】  


# Lua脚本
①`EVAL`执行一段lua脚本，每次都需要将完整的lua脚本传递给redis服务器  
②`SCRIPT LOAD`将一段lua脚本缓存到redis中并返回一个tag串，并不会执行  
③`EVAL SHA`执行一个脚本，不过传入参数是②中返回的tag，节省网络带宽  
④`SCRIPT EXISTS`判断②返回的tag串是否存在服务器中  
⑤`SCRIPT FLUSH`清除服务器上的所有缓存的脚本  
⑥`SCRIPT KILL`杀死正在运行的脚本  
⑦`SCRIPT DEBUG`设置调试模式，可设置同步、异步、关闭，同步会阻塞所有请求  



https://www.jb51.net/article/155720.html




