# 大事务可能会对数据库造成什么问题
① 锁定数据过多，容易造成大量的死锁和锁超时  
> 有两种策略可以处理死锁  
> ① 等待死锁超时，超时时间（innodb_lock_wait_timeout）默认是50s，这个时间很长，但是也不能太小，怕影响到本可以正常消除的死锁  
> ② 死锁检测，死锁检测的配置默认是开启的，死锁检测就是每当一个事务被锁的时候，就要看看他所依赖的线程有没有被别

② 回滚记录占用大量存储空间，事务回滚时间长
> 每条记录在更新的时候都会同时记录一条回滚操作，记录上的最新值，通过回滚操作，都可以得到前一个状态的值  
> 当没有事务需要用到这些回滚日志时，也就是系统里没有比这个回滚日志更早的read-view的时候，回滚日志才会被删除，实际上就是在这些事务提交之后

③ 执行时间长，容易造成主从延迟
> 因为主库上必须等事务执行完成之后才会写入binlog，再传给备库，所以如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟

# 如何解决大事务的问题
```
https://cloud.tencent.com/developer/article/1595282
```
① 少用@Transactional注解，通过编程式事务，使用```TransactionTemplate```手动执行事务，并将查询放到事务之外  
② 事务中避免远程调用，事务中避免一次性处理太多数据；不是所有数据库操作都需要在事务中执行，有些方法可以非事务执行  
③ 改变思路，将同步更新转异步发送mq消息处理  
④ 基于事务的隔离级别  
> mysql默认的隔离级别是可重复读，在这个隔离级别下写数据的时候会有这些问题  
> ① 如果有索引（包括主键索引）的时候，以索引列为条件更新数据，会存在间隙锁、行锁、下一键锁的问题，从而锁住一些行  
> ② 如果没有索引，更新数据时会锁住整张表  
> 如果把隔离级别改为读已提交就不存在这些问题了，每次写数据只会锁一行，但同时要解决可能出现的数据和日志不一致问题，需要把binlog格式设置为row

⑤ 通过```SETMAX_EXECUTION_TIME```命令， 来控制每个语句执行的最长时间，避免单个语句意外执行太长时间  
⑥ 监控```information_schema.Innodb_trx```表，设置长事务阈值，超过就报警/或者kill  
⑦ 在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题  
⑧ 设置```innodb_undo_tablespaces```值，将undo log分离到独立的表空间。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便