# JVM锁在多进程场景下问题
1、多例模式下锁失效  
2、事务隔离级别设置成读未提交可以解决锁失效问题，但是一般不设置成读未提交，而读已提交和可重复读都可能会引起锁失效  
3、集群部署环境下

# 基于Mysql关系型数据库实现分布式锁
> 完全依靠Mysql来解决并发问题的思考  
> 下面这条SQL语句完成了查询判断及数量更新，巧妙解决了在业务代码中存在的并发问题  
> update db_stock set count = count -1 where product_code = '1001' and count >= 1
>
> 存在问题：  
> ① 锁的范围问题。MySQL悲观锁中想要使用行级锁，必须得给查询条件或者更新条件的字段上加索引，加了索引后也不能让其失效，否则会给全表加锁
> ② 业务复杂时，一条SQL语句无法办到，必须在业务代码中判断  
> ③ 不能记录库存变化前后的状态
>
> 其他方案一：悲观锁解决并发问题  
> 编写SQL语句```select * for update```。通过for update已经锁定了相应行记录，不用担心其他事务的修改，其他事务的修改会被阻塞。
> 再通过程序控制选择一条记录进行扣减，并记录库存扣减前后状态变化。但是存在性能问题，死锁问题等，并不推荐
>
> 其他方案二：乐观锁解决并发问题  
> 乐观锁的方式在高并发情况下，也会存在性能问题。ABA问题。读写分离情况下，导致乐观锁不可靠，因为从机读取数据的版本总是有延迟，
> 不是新version，导致主机更新一直失败
>
> MySQL解决并发问题总结  
> 性能：一条sql > 悲观锁 > jvm锁 > 乐观锁  
> 如果追求极致性能，业务场景简单并且不需要记录数据前后变化的情况下，优先选择一条sql。  
> 如果写并发量较低（多读），争抢不是很激烈的情况下，优先选择乐观锁。  
> 如果写并发量较高，一般会经常冲突，此时如果选择乐观锁的话，会导致业务代码不间断的重试，所以优先选择mysql悲观锁。  
> 不推荐jvm本地锁

通过数据库的方式实现分布式锁的效果，实际就是借助于数据库的唯一约束（或者for update）来实现
```
考虑要点：  
① 排他性基于唯一索引实现  
② 死锁问题：客户端程序获取到锁之后，客户端程序宕机。可以通过给记录加一个获取锁的时间列，然后通过```另外的服务```的定时任务检查获取锁
的时间和当前系统时间的差值是否超过了阈值，超过则删除，即过期自动释放了锁  
③ 防误删问题：借助于字段值的唯一性防止误删锁  
④ 原子性问题：写数据本身会开启事务，即可保证原子性。为了防止锁重入问题，会存在多个sql语句同时执行需要保证原子性的问题，此时可以借助于mysql的悲观锁来实现  
⑤ 可重入问题：通过记录服务器信息、线程信息以及重入次数来保证可重入性  
⑥ 自动续期：```服务器内的定时任务```重置获取锁的系统时间  
⑦ 单机故障：如果数据库出现故障，可能会导致平台中的业务异常， 搭建MySQL主备  
⑧ 集群情况下锁机制失效问题（主数据库写完数据后宕机，还没来得及同步数据，此时从数据库是没有把锁信息同步过来的，其他线程连接从库，能够重新获得锁）  
```

# 基于redis的setNx命令实现分布式锁
### 加锁阶段
① 加锁：客户端程序异常未解锁导致死锁，为防死锁给锁增加过期时间```set key value ex 20 nx```  
> 加锁不成功时，再次获得锁用while循环的方式，不要用递归调用，递归调用导致多个栈帧入栈等待，最后库存扣减量等于栈帧的数量，而不是减1

② 可重入性问题：不可重入导致死锁问题  
> 通过hash结构和Lua脚本实现可重入锁  
> 判断锁是否被占用，如果没有被占用则直接获取锁（```hset/hincrby（field为0时也可以增加）```），并设置过期时间（expire）  
> 如果锁被占用，则判断是否是当前线程占用锁（```hexists```），如果是则重入（```hincrby```），并设置过期时间  
> 否则在代码中通过重试再次获取锁

```
// 用Lua脚本实现非公平的可重入锁的加锁过程
if redis.call('exists',KEYS[1]) == 0 or redis.call('hexists',KEYS[1],ARG[1]) == 1
then
    redis.call('hincrby',KEYS[1],ARG[1],1)
    redis.call('expire',KEYS[1],ARG[2])
    return 1
else
    return 0
end

// 用Lua脚本实现非公平的可重入锁的解锁过程
if redis.call('hexists',KEYS[1],ARGV[1]) == 0
then
    return nil
elseif redis.call('hincrby',KEYS[1],ARGV[1], -1) == 0
then
    return redis.call('del',KEYS[1])
else
    return 0
end
```

③ 自动续期问题：可以通过Timer定时器 + Lua脚本来解决
```
if redis.call('hexists',KEYS[1],ARGV[1]) == 1
then
    return redis.call('expire',KEYS[1],ARGV[2])
else
    return 0
end
```

### 解锁阶段
① 解锁：设置uuid值防误删，通过```lua脚本```保证判断和删除是原子的
```
// 一定要用两个参数的构造器，一个参数的构造器很可能会报错
redisTemplate.execute(new DefaultRedisScript<>(script, Integer.class),Arrays.asList("lock"),uuid);
```

> 解重入锁：用lua脚本实现先判断value再删除，这样能保证原子性和防误删  
> hash结构 + lua脚本实现可重入解锁  
> 判断当前线程的锁是否存在，不存在则返回null，将来抛出异常  
> 存在则直接减1（```hincrby -1```），判断减1后的值是否为0，为0则释放锁（```del```），并返回1，代表释放锁成功  
> 不为0，表示释放了一层锁，还不到解锁的时候，则返回0

### redis 作为分布式锁存在单点问题

## redisson
```
@Bean
public RedissonClient redissonClient(){
    Config config = new Config();
    config.useSingleServer().setAddress("redis://ip:port");
    return Redisson.create(config);
}
```

① 可重入锁RLock对象
```
RLock lock = this.redissonClient.getLock("xxx");
lock.lock()/unlock();
```

② 公平锁：基于排序队列实现
```
RLock lock = this.redissonClient.getFairLock("xxx");
lock.lock()/unlock();
```

③ 联锁和红锁  
联锁不推荐使用，需要所有redis节点获取锁成功，才能获取锁成功  
红锁半数以上节点获取锁成功，可以研究一下红锁算法  

④ 读写锁
```
RReadWriteLock rwLock = this.redissonClient.getReadWriteLock("xxx");
rwLock.readLock().lock()/unlock();
rwLock.writeLock().lock()/unlock();
```

⑤ 信号量
```
RSemaphore semaphore = this.redissonClient.getSemaphore("xxx");
semaphore.trySetPermits(3);
semaphore.acquire()/release();
```

⑥ 闭锁
```
RCountDownLatch cdl = this.redissonClient.getCountDownLatch("xxx");
cdl.trySetCount(6);
cdl.await()/countDowntch();
```

# 基于zk实现分布式锁
```
https://cloud.tencent.com/developer/news/893351
```

# 分布式锁总结
① 简易程序：mysql > redis(lua脚本) > zk  
② 性能：redis > zk > mysql  
③ 可靠性：zk > redis = mysql  
最佳实践：  
追求性能的应用可以用redis。追求可靠性的应用可以用zk。简单实现，对性能、可靠性要求都不高的情况下，可以选择用msql实现分布式锁  
当多个请求同时到达时，如果不借助db的事务，很容易造成行锁竞争，但用事务的话，db的性能显然比不上redis轻量。