# 使用场景（需不断更新）
① 缓存  
② 计数器  
③ 最新列表  
使用list结构的```lpush```来装载用户订阅的文章的id，``` lpush 用户id 文章id 文章id ```，之后要查看某人自己订阅的全部文章，可以用```lrange 用户id 0 10 ```，查看用户订阅的文章的前10条  
④ 排行榜  
可以用list结构实现，但是更多用```zset```结构实现。但是sorted set类型占用的内存容量是list类型的数倍之多
⑤ 分布式锁  

> set  
> 在微信抽奖小程序时，如果某用户立即参与抽奖，```sadd key 用户id```，显示已经有多少人参与了抽奖，用```scard key```，抽奖的时候，从set中任意选取N个中奖人，  
> ```srandmember key 2``` 随机抽奖2个人，元素不删除。```spop key 3```随机抽奖3个人，元素会删除。  
> 在朋友圈点赞时，记录新增点赞的功能时，可以用```sadd 发布的消息的id 点赞用户id1 点赞用户id2```  
> 取消点赞时，可以使用```srem 发布的消息的id 点赞用户id```  
> 展现所有点赞过的用户，```smembers 发布的消息的id```，在这里罗列的就是所有点赞过的用户的头像  
> 点赞用户数统计，就是常见的点赞红色数字，```scard 发布的消息的id```  
> 判断某个朋友是否对楼主点赞过，```sismember 用户id 发布的消息的id```  
> 在设计微博好友的社交关系时，共同关注的人可以取集合的交集，```sinter key1 key2```  
> 在推荐好友的时候，可以取差集运算，如```sdiff key1 key2```，此时得到的结果是key1中存在，key2中不存在，因此可以将这个结果推荐给key2，作为可能认识的人。  

> ```zset```  
> 根据商品销售量对商品进行排行显示，定义商品销售排行榜，key为```goods:sellsort```，分数为商品销售数量  
> 商品编号为1001的销量是9，商品编号1002的销量是15，```zadd goods:sellsort 9 1001 15 1002```  
> 有一个客户又买了2件商品1001，商品编号 1001 销量加2，```zincrby goods:sellsort 2 1001```  
> 求商品销量前10名，```zrevrange goods:sellsort 0 10 withscores（从高到低）,zrange（从低到高）```  
> 抖音热搜排行榜，点击视频时，点击量加1，```zincrby hotvcr:20200919 1 八佰```  
> 如果要展示当日排行榜前10条时，可以使用```zrevrange hotvcr:20200919 0 9 withscores```  

# 单线程理解
单进程模型来处理客户端的请求，对读写等事件的响应是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率。  
Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。

不使用多线程的原因：  
① 使用redis，CPU不再是瓶颈，受制于内存和网络  
② 通过使用Pipeline（命令批量）的方式可以提高redis处理速度，达到每秒100万个请求  
③ 单线程的方式，内部维护成本低，因为多线程存在线程切换、加锁/解锁、死锁等问题  

# 持久化
## RDB
【概念】  
在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的Snapshot快照。恢复时是将快照文件移动到安装目录后启动服务器即可，它会读取到内存中。RDB保存的是dump.rdb文件。  

【实现原理】  
redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要
比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。  
fork说明：  
fork的作用是复制一个与当前进程一样的进程，新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。  

【如何触发RDB快照】  
①save：只管保存，其他不管，全部阻塞  
②BGSave：redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过lastSave命令获取最后一次成功执行快照的时间  
③执行flushAll命令，也会产生dump.rdb文件，但里面是空的，无意义  

【优势】  
适合大规模的数据恢复，对数据完整性和一致性要求不高  

【劣势】  
①在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改  
②fork的时候，内存中的数据被克隆了一份，大至2倍的膨胀性需要考虑  

【常用命令】  
① config set save ""  // 动态停止RDB保存规则
② config get dir      // 获取安装目录

## AOF
【概念】  
以日志的形式来记录每个写操作，将redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新
构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。AOF保存的是appendOnly.aof文件。  

【恢复】  
先修改appendOnly no为yes，将有数据的aof文件复制一份保存到安装目录，若文件异常，则启动会报错，需要先用```redis-check-aof --fix```指令进行修复，然后重启redis即可

【rewrite】  
AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，
只保留可以恢复数据的最小指令集。可以使用命令```bgrewriteaof```。  
AOF文件持续增大而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条set语句。重写
aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。  
redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。  

【优势】  
①每修改同步```appendfsync always```，同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好  
②每秒同步```appendfsync everysec```，异步操作，每秒记录，如果一秒内宕机，有数据丢失  
③不同步```appendfsync no```，从不同步  

【劣势】  
①相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb  
②aof运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同  

## 持久化总结
①RDB持久化方式能够在指定的时间间隔对你的数据进行快照存储  
②AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾。
redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。  

③当同时开启两种持久化方式时，在这种情况下，redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下，AOF文件保存的数据集要比RDB文件
保存的数据集要完整。  
RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件，但是也不要只使用AOF文件，因为RDB更适合用于备份数据库，AOF文件
在不断变化不好备份，而且存在潜在的BUG。  

### 建议
因为RDB文件只用作后备用途，建议只在slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。  
如果enable aof，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本简单只load自己的aof文件就可以了。代价是带来了持续的IO，而且
AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，
AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。  
如果不enable aof，仅靠master-slave replication实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果master/slave
同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个master/slave中的RDB文件，载入较新的那个。

# redis的复制
【概念】  
也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slave机制，master以写为主，slave以读为主。  
可以实现读写分离和容灾恢复  
【操作步骤】  
①配从库不配主库  
②从库配置：slaveof 主库IP 主库端口。每次与master断开之后，都需要重新连接，除非你配置进redis.conf文件  
③需要拷贝多个redis.conf文件，并且开启daemonize yes，然后指定pid文件名字，指定端口号，修改log文件名字，修改dump.rdb文件名字  
```
info replication
```
【常用方案】  
①一主二仆：一个master两个slave
问题思考：  
切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制？比如从k4进来后，那么之前的123是否也可以复制？  
从机是否可以写？set可否？  
主机shutdown后情况如何？从机是上位还是原地待命？  
主机又回来了后，主机新增记录，从机还能否顺利复制？  
其中一台从机down掉后，依照原有它能跟上大部队吗？  
②薪火相传：上一个slave可以是下一个slave的master，slave同样可以接收其他slaves的连接和同步请求，那么该slave作为了链条中下一个的master，
可以有效减轻master的写压力。  
中途变更转向：会清除之前的数据，重新建立拷贝最新的  
③salveof no one：使当前数据库停止与其他数据库的同步，转成主数据库  
【复制原理】  
①slave启动成功连接到master后会发送一个sync命令  
②master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，
以完成一次完全同步。  
③全量复制是slave服务在接收到数据库文件数据后，将其存盘并加载到内存中  
增量复制是master继续将新的所有收集到的修改命令依次传给slave，完成同步  
但是只要是重新连接master，一次完全同步（全量复制）将被自动执行
【复制缺陷】  
由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，
当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。
## 哨兵模式
能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换位主库。  
【实现步骤】  
①新建sentinel.conf文件，名字不能出错  
```sentinel monitor 被监控数据库名字 127.0.0.1 6379 1（最后的数字1，表示主机挂掉后slave投票看让谁接替成为主机，得票数多少后成为主机）```  
②启动哨兵  
redis-sentinel ...sentinel.conf
**问题：如果之前的master重启回来，不会造成双master冲突，之前的master会变成slave加入集群中**

# 使用场景
【分布式锁】  
第一步：  
使用redis实现分布式锁，首先需要保证加锁【①+②】和删除锁【③+④】的原子性  
①set key value NX（不存在才设置值）  
②set key value EX 100 NX（设置过期时间）  
③判断分布式锁的值与当前线程保存的值是否相等，相等才发删除该锁的命令  
④delete key  
第二步：  
保证③和④的原子性操作需要使用Lua脚本：  
String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end"
第三步：  
锁的自动续期  

【redisson】  
lock.lock()  
阻塞式等待：默认加的锁都是30S时间  
1）、锁的自动续期，如果业务超长，运行期间自动给锁续上新的30S。不用担心业务时间长，锁自动过期被删掉  
2）、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30S以后也会自动删除  
3）、只要占锁成功，就会启动一个定时任务，该定时任务的作用是重新给锁设置过期时间，新的过期时间就是看门狗的默认时间，每隔10秒，
都会将锁的过期时间重新设置成30S

lock.lock(10,TimeUnit.SECONDS)  
**10秒自动解锁，自动解锁时间一定要大于业务的执行时间**  【因为没有自动续期功能，不这样设置会导致锁的误删问题】  
注意：此方法在锁时间到了以后，不会自动续期  
1）如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时时间就是我们指定的时间  
2）如果我们未指定锁的超时时间，就使用30*1000【LockWatchDogTimeOut看门狗的默认时间】  

# Lua脚本
①`EVAL`执行一段lua脚本，每次都需要将完整的lua脚本传递给redis服务器  
②`SCRIPT LOAD`将一段lua脚本缓存到redis中并返回一个tag串，并不会执行  
③`EVAL SHA`执行一个脚本，不过传入参数是②中返回的tag，节省网络带宽  
④`SCRIPT EXISTS`判断②返回的tag串是否存在服务器中  
⑤`SCRIPT FLUSH`清除服务器上的所有缓存的脚本  
⑥`SCRIPT KILL`杀死正在运行的脚本  
⑦`SCRIPT DEBUG`设置调试模式，可设置同步、异步、关闭，同步会阻塞所有请求  

# redis内存相关
1 如何查看内存大小？在配置文件中的859行 ```maxmemory <bytes>```，注意此处内存大小是bytes字节类型，注意单位转换。  
如果不设置最大内存大小或者设置最大内存大小为0，在64位操作系统下不限制内存大小，在32位操作系统下最多使用3GB内存。还可以通过```info maxmemory```命令查看redis的内存使用情况  
一般生产上的配置：一般推荐redis设置内存为最大物理内存的四分之三。既可以通过修改配置文件的大小，也可以通过```config set maxmemory``` 内存大小进行设置

2 redis过期键的删除策略：
> redis打满了，会报错  
> (error) OOM command not allowed when used memory > ```maxmemory```

① 定时删除：即检测被设置了生存时间的key，判断是否达到过期时间，达到即删除。这样对cpu不友好，有一个定时任务时刻在消耗CPU的性能，用处理器性能去换存储空间  
② 惰性删除：即下次访问数据时再判断是否到达过期时间，这样对内存不友好，即使很多键已经过期了，但是没有第二次访问（或者执行flushDb可以清除过期key），因此也不会被删除，导致内存中有很多的过期键，用存储空间去换处理器性能  
③ 定期删除：上述两种方案同时使用。这是前面两种删除策略的折中：每隔一段时间执行一次删除过期键操作，并通过限制删除操作执行的**时长**和**频率**来减少删除操作对CPU时间的影响。  
此时依然存在问题：在抽样key时，有key从来没有被抽样到，所以依然大量过期的key堆积在内存中，导致redis内存空间紧张或者很快耗尽

在上述方案执行之后，如果内存达到阈值时，就会触发内存淘汰策略  
生产上，在配置时一般使用```maxmemory-policy allkeys-lru```，命令（```config set maxmemory-policy allkeys-lru```）和修改配置文件都可
> 内存淘汰策略（八种）  
第一种：```noeviction```，不会驱逐任何key，在新加时会报异常（6.0.8默认）  
第二种：```allkeys-lru```，对所有key使用LRU算法进行删除（生产上常用）  
第三种：```volatile-lru```，对所有设置了过期时间的key使用LRU算法进行删除  
第四种：```allkeys-random```，对所有key进行随机删除  
第五种：```volatile-random```，对所有设置了过期时间的key随机删除  
第六种：```volatile-ttl```，删除马上要过期的key  
第七种：```allkeys-lfu```，对所有key使用LFU算法进行删除  
第八种：```volatile-lfu```，对所有设置了过期时间的key使用LFU算法进行删除

# LRU
手写LRU算法？

https://www.jb51.net/article/155720.html




# 验证快照文件和AOF文件
redis提供了两个命令，用来在系统宕机后检查快照文件和aof文件的状态，并进行修复
redis-check-dump(修复快照)  目前没有办法修复出错的快照文件，因为快照文件本身时进行过了压缩，快照中的错误可能会导致剩余不问无法读取，解决办法是将重要的快照保留多个备份，在后期的数据恢复是通过计算快照文件的SHA1散列值和SHA256散列值来对内容进行验证
redis-check-aof(修复aof)  用户运行redis-check-aof --fix,程序将会对文件修复，扫描aof文件找出第一个出错的命令，并且删除出错命令之后的所有命令，只保留那些为出错的命令，在大多情况下，被删除的都是aof文件末尾的不完整的命令

# redis的高级特性和应用
### redis的慢查询
