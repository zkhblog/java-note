# redis优势
① 具备高性能。数据缓存在内存中，操作redis速度很快
② 具备高并发。单机redis的QPS可以突破10w，而mysql很难突破1w，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的

# 使用场景
### String
缓存对象、常规计数、分布式锁、共享session信息等  

### List
消息队列、获取最新列表(```lpush```、```lrange```)等

### Hash
缓存对象

### Set
聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等

### ZSet
排序场景，比如排行榜、电话和姓名排序等

# redis单线程模型
指redis的网络IO和键值对读写是由一个线程来完成的，redis在处理客户端的请求时包括读取（socket读）、解析、执行、内容返回（socket写）等都由一个顺序串行的主线程处理，这就是所谓的单线程。redis采用reactor模式的网络模型，对于一个客户端请求，主线程负责一个完整的处理过程。但是Redis的其他功能，比如RDB或AOF持久化、异步删除、集群数据同步等，是由额外的线程执行的。因此Redis命令工作线程是单线程的，但是整个Redis来说，是多线程的。

### redis单线程快的原因

①基于内存操作，性能比较高

②数据结构简单，这些简单的数据结构的查找和操作的时间复杂度大部分都是O(1)

③使用IO多路复用机制来监听多个socket连接客户端，这样就可以使用一个线程连接来处理多个请求，减少线程切换的开销，同时也避免了IO阻塞操作

④单线程模型避免了不必要的上下文切换和多线程竞争，这样省去了多线程带来的时间和性能上的消耗，而且单线程不会导致死锁问题的发生



### 不使用多线程的原因

①单线程模型使redis的开发和维护更简单

②即使使用单线程模型也能并发的处理多客户端的请求，主要使用的是IO多路复用机制和非阻塞IO

③对于redis系统来说，主要的性能瓶颈是内存或者网络带宽而并非CPU

### redis6.0之后为什么引入多线程

为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理

### 单线程的问题

当del bigKey时，被删除的key是一个大对象时，del指令就会造成Redis主线程卡顿，等待很久这个线程才会释放，类似加了一个锁，在高并发场景中是不允许的

解决方案：引入多线程来实现数据的异步删除。但处理读写请求命令仍然只有一个线程，所以仍然算是狭义的单线程。

①unlink key

②flushdb async

③flushall async

# 持久化
### RDB
将某一时刻的内存数据，以二进制的方式写入磁盘。恢复时是将快照文件移动到安装目录后启动服务器即可，它会读取到内存中。RDB保存的是dump.rdb文件。  

##### 如何实现
Redis 提供了两个命令来生成 RDB 文件，分别是save和bgsave。

save命令执行同步操作将当前redis实例的数据快照以文件形式保存到磁盘，此种方式阻塞主进程。

bgsave命令会fork出子进程，而原来父进程继续处理客户端的请求，子进程负责将数据保存到磁盘。

执行flushAll命令，也会产生dump.rdb文件，但里面是空的。  

```
①Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次bgsave命令，默认会提供以下配置：
save 900 1      // 900 秒之内，对数据库进行了至少 1 次修改  
save 300 10     // 300 秒之内，对数据库进行了至少 10 次修改  
save 60 10000   // 60 秒之内，对数据库进行了至少 10000 次修改
②fork的作用是复制一个与当前进程一样的进程，新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。
```



##### 特点

①如果**需要进行大规模数据的恢复**，且**对于数据恢复的完整性不是非常敏感**，那RDB方式要比AOF方式更加的高效

②可以按照业务定时备份。RDB文件在内存中的加载速度要比AOF快很多

③在间隔一定时间做一次备份，可能会丢失从当前至最近一次快照期间的数据

④内存数据的全量同步，如果数据量太大会导致IO严重影响服务器性能

##### 其他命令

save "" 						// 禁用RDB

appendonly no 				// 禁用AOF

config set save ""  			// 动态停止RDB保存规则

config get dir      				// 获取安装目录

redis-check-rdb ./redisconfig/dump.rdb // 检查修复dump.rdb文件

##### 触发RDB时机

①配置文件中的快照配置

②手动save/bgsave命令

③执行flushdb/flushall命令也会产生dump.rdb文件，但是这个文件无作用

④执行shutdown且没有设置开启AOF持久化

⑤主从复制时，主节点自动触发

### AOF
**以日志形式来记录每个写操作**。 将redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但是不可改写文件，redis启动之处会读取该文件重新构建数据，实际上就是根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

开启AOF功能需要设置配置：```appendonly yes```。

AOF保存的是appendOnly.aof文件。  

因为执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。

##### AOF写日志策略

命令到达Server后并不是直接写入AOF文件，而是先放入AOF缓存中进行保存，当这些命令达到一定量以后再写入磁盘，避免了频繁的磁盘IO操作。

①```appendfsync always```，同步写回，每个写命令执行完立刻同步地将日志写入磁盘，性能较差但数据完整性比较好。
② ```appendfsync everysec```，每秒写回，每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔1秒把缓冲区的内容写入到磁盘。

③```appendfsync no```， 每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回到磁盘。

##### AOF重写机制

为避免AOF文件膨胀，会根据规则进行命令的合并（又称AOF重写），从而起到AOF文件压缩的目的。简单说就是启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。Redis的重写AOF过程是由后台子进程来完成的，重写过程中，主进程依然可以正常处理命令，接收到的新命令会在子进程生成新的AOF文件后被写入其中。

①手动触发方式

客户端向服务器发送bgrewriteaof命令

②自动触发方式

满足配置文件中的选项后，redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64m时。

##### AOF恢复异常
先修改appendOnly no为yes，将有数据的aof文件复制一份保存到安装目录，若文件异常，则启动会报错，需要先用```redis-check-aof --fix```指令进行修复，然后重启redis即可。程序将会对文件修复，扫描aof文件找出第一个出错的命令，
并且删除出错命令之后的所有命令，只保留那些没出错的命令，在大多情况下，被删除的都是aof文件末尾的不完整的命令。

##### 特点

①数据丢失更少，只丢失1秒钟的写入。

②相同数据集的AOF文件和RDB文件，AOF文件恢复速度慢于RDB。

③一般将AOF设置成每秒同步策略效率较好。

### 混合持久化（推荐）

①在redis.conf文件中设置以下参数，可以开启混合持久化

```
aof-use-rdb-preamble yes # 设置yes表示开启，no表示禁用
```

②RDB镜像做全量持久化，AOF做增量持久化 先使用RDB进行快照存储，然后使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。

# pipeline

管道可以一次性发送多条命令给服务端，减少了客户端和服务端的通信次数。实现原理是队列，先进先出的特性保证了数据的顺序性。

管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能。使用管道技术可以解决多个命令执行时的网络等待。

### 特点

①原生批量命令是原子性的（例如mset、mget），**pipeline是非原子性的**。

②原生批量命令一次只能执行一种命令，pipeline支持批量执行不同命令。

③管道中的某个命令执行失败，客户端需要单独处理每个命令的错误。

### 注意点

①pipeline缓冲的指令只是会依次执行，不保证原子性，如果执行中指令发生异常，将会继续执行后续的指令。

②使用pipeline组装的命令个数不能太多，不然数量过大客户端阻塞的时间可能过久，同时服务端也被迫回复一个队列的答复，占用很多内存。

# 发布订阅

发送者(PUBLISH)发送消息，订阅者(SUBSCRIBE)接收消息。

但是不推荐使用该功能。

```
PUB/SUB缺点
①发布的消息在Redis系统中不能持久化，因此，必须先执行订阅，在等待消息发布。如果先发布了消息，那么该消息由于没有订阅者，消息将被直接丢弃。
②消息只管发送，对于发布者而言消息是即发即失，不管接受，也没有ACK机制，无法保证消息的消费成功。
以上的缺点导致Redis的Pub/Sub模式就像个小玩具，在生产环境中几乎无用武之地，为此Redis5.0版本新增了Stream数据结构，不但支持多播，还支持数据持久化，相比Pub/Sub更加的强大。
```



# Lua脚本

①`EVAL`执行一段lua脚本，每次都需要将完整的lua脚本传递给redis服务器  
②`SCRIPT LOAD`将一段lua脚本缓存到redis中并返回一个tag串，并不会执行  
③`EVAL SHA`执行一个脚本，不过传入参数是②中返回的tag，节省网络带宽  
④`SCRIPT EXISTS`判断②返回的tag串是否存在服务器中  
⑤`SCRIPT FLUSH`清除服务器上的所有缓存的脚本  
⑥`SCRIPT KILL`杀死正在运行的脚本  
⑦`SCRIPT DEBUG`设置调试模式，可设置同步、异步、关闭，同步会阻塞所有请求  

# redis过期删除与内存淘汰
① 如何查看内存大小？在配置文件中的859行 ```maxmemory <bytes>```，注意此处内存大小是bytes字节类型，注意单位转换。  
② 如果不设置最大内存大小或者设置最大内存大小为0，在64位操作系统下不限制内存大小，在32位操作系统下最多使用3GB内存。还可以通过```info maxmemory```命令查看redis的内存使用情况  
③ 一般生产上的配置：一般推荐redis设置内存为最大物理内存的四分之三。既可以通过修改配置文件的大小，也可以通过```config set maxmemory``` 内存大小进行设置  
④ redis打满了，会报错：(error) OOM command not allowed when used memory > ```maxmemory```

### 过期删除策略
① 惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。  
③ 定期删除：每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。  
此时依然存在问题：在抽样key时，有key从来没有被抽样到，所以依然大量过期的key堆积在内存中，导致redis内存空间紧张或者很快耗尽。  
所以 Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。

### 内存淘汰策略
在上述方案执行之后，如果内存达到阈值时，就会触发内存淘汰策略  
生产上，在配置时一般使用```maxmemory-policy allkeys-lru```，命令（```config set maxmemory-policy allkeys-lru```）和修改配置文件都可
> 内存淘汰策略（八种）  
> ```noeviction```：不会淘汰任何key，在新加时会报异常（6.0.8默认）  
>
> 在设置了过期时间的数据中进行淘汰  
> ```volatile-random```：随机淘汰设置了过期时间的任意键值  
> ```volatile-ttl```：优先淘汰更早过期的键值  
> ```volatile-lru```：淘汰所有设置了过期时间的键值中，最久未使用的键值  
> ```volatile-lfu```：淘汰所有设置了过期时间的键值中，最少使用的键值
>
> 在所有数据范围内进行淘汰  
> ```allkeys-random```：随机淘汰任意键值  
> ```allkeys-lru```：淘汰整个键值中最久未使用的键值（生产上常用）  
> ```allkeys-lfu```：淘汰整个键值中最少使用的键值  

### LRU
LRU 算法的实现是基于链表结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，
只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素  
Redis 实现的是一种近似 LRU 算法，目的是为了更好 的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，
用于记录此数据的最后一次访问时间。
```
https://www.jb51.net/article/155720.html
```

### LFU
LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，
数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。

# redis分布式锁

### 主要考点

```
自研的redis锁对于一般中小公司，不是特别高并发场景足够用了，单机redis小业务也撑得住
```



①lock加锁

加锁要设置过期时间（可以使用lua脚本保证设值和设值过期时间的原子性）

使用hash数据结构保证加锁功能和锁的可重入性

加锁不成，需要while进行重试并自旋

在过期时间内，业务未完成，锁要自动续期

②unlock解锁

在finally中释放锁时，删除自己的锁（判断和删除可以使用lua脚本保证原子性）

考虑可重入性，加锁几次就要解锁几次

### redlock

redis集群主从复制时，由于master节点数据未来得及同步到slave，slave上位后，可能出现多个线程都写入了键值对，此时出现了多个线程加锁成功的错误现象。





# 总结 

①pipeline是非原子的，lua脚本在redis服务器上执行时具有原子性。

② 