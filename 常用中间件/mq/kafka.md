----------------------------------
https://blog.csdn.net/heyutao007/article/details/50131089
https://blog.csdn.net/lzb348110175/article/details/100773487

----------------------------------

# 消息队列的两种模式
1 点对点模式  
消息生产者生产消息发送到queue中，然后消费者从queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消费者不可能消费到已经被消费的消息。
Queue支持存在多个消费者，**但是对一个消息而言，只会有一个消费者可以消费**。  

2 发布/订阅模式  
生产者将消息发布到 topic 中，同时有多个消费者订阅该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。而且费者消费数据之后topic不会清除消息  

3 区别  
3.1 发布订阅模式下，当发布者消息量很大时，显然单个订阅者的处理能力是不足的。实际上现实场景中是多个订阅者节点组成一个订阅组负载均衡消费topic消息即分组订阅，
这样订阅者很容易实现消费能力线性扩展。**可以看成是一个topic下有多个Queue，每个Queue是点对点的方式，Queue之间是发布订阅方式。**  
3.2 生产者发送一条消息到queue，一个queue可以有很多消费者，但是一个消息只能被一个消费者接受，当没有消费者可用时，这个消息会被保存直到有一个可用的消费者，
所以Queue实现了一个可靠的负载均衡。  
3.3 发布者发送到topic的消息，只有订阅了topic的订阅者才会收到消息。topic实现了发布和订阅，当你发布一个消息，所有订阅这个topic的服务都能得到这个消息，
所以从1到N个订阅者都能得到这个消息的拷贝。

# Kafka基础
① Kafka分区数量只能增加不能减少  
② 不能通过命令行的方式修改副本数量

# Kafka生产者
### 普通异步发送

### 带回调函数的异步发送

### 同步发送

### 数据同步策略

### Kafka分区
每个分区在一个Broker上存储，可以把海量的数据按照分区切割成一块一块数据存储在多台Broker上

### 数据可靠性
ACK应答机制  
```acks```参数设置：0、1、-1
> ack等于-1的问题  
> ① 更多情况下会造成数据重复的问题，因为在isr中的全部follower同步完数据后，还没发ack时，此时Leader故障，那么生产者重新发送数据到新的Leader，那么同步数据流程又走了一遍  
> ② 也可能会造成数据丢失，因为当副本只有一个时，即Leader，此种特殊情况下，也可能在L故障后丢失数据  
> ③ Leader收到数据后，所有Follower都开始同步数据，如果有一个Follower因为某种故障迟迟不能与Leader进行同步，解决这种问题的办法如下  
> Leader维护一个isr，isr里面是与Leader保持同步的Follower和Leader集合。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出isr，该时间阈值由  
> ```replica.lag.time.max.ms```参数设定，默认值为30s，这样就不用等长期联系不上或者已经故障的节点

> 数据完全可靠条件 = ACK级别设置为1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2

### 数据去重
至少一次（At Least Once） = ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的最小副本数量大于等于2。可以保证数据不丢失，但是不能保证数据不重复  
最多一次（At Most Once） = ACK级别设置为0。可以保证数据不重复，但是不能保证数据不丢失  
精确一次（Exactly Once） ，要求数据既不能重复也不能丢失

### 数据有序

1 半数以上策略  

2 全部同步策略  
Kafka选择了此种策略，且**对这种策略进行了优化**。Leader维护了一个动态的isr，isr保存了和leader保持同步的follower集合。follower长期未向leader同步数据
（在指定时间内未同步完成），则该follower将被剔出isr。该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障后，就会从isr中选举新的leader。  
> 长期未同步策略还有指定次数这一种，比如限制F和L的最大差是10条，但是生产者批次发送，一次发送了12条，导致F在同步L的数据的时候，差距就是12条，因此根据限制，F会被移除isr，
> 但是在指定的完成同步时间范围内，又将12条数据全部同步完成。此时F又被加入isr。因此指定次数的问题就是会导致F在isr中频繁移除和移入，而且zk中也会记录isr的信息，因此也会
> 频繁变更zk中的信息。

### HW值
HW是消费者能见到的最大的offset，还是isr队列中最小的LEO(Log end offset)  
两点作用：  
① 保证了消费者消费数据的一致性  
② Leader故障时，其余Follower会将各自的log文件高于HW的部分截掉，重新从新的Leader同步数据，因此这保证了副本之间数据的一致性，但是并不能保证数据不丢失或者不重复  

### Exactly Once
ack设置为-1时，至少发一次消息(AtLeast Once) + 幂等性 = Exactly Once  

0.11版本的Kafka提供了幂等性。要启用幂等性，只需要将Producer的参数中```enable.idompotence```设置为true，Kafka的幂等性的实现其实就是将原来消费者需要逻辑去重的流程放在了
数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对<PID,Partition,SeqNumber>做缓存，
当具有相同主键的消息提交时，Broker只会持久化一条。但是PID重启就会发生变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once  

# Kafka消费者
## 消费方式


## 分区分配策略

## 










