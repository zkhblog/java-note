# 消息防丢失方案
## 生产阶段
生产者开启请求确认机制。客户端收到确认响应，就代表完成了一次正常的消息发送  
补偿机制是开启定时任务，继续投送未正常发送的消息。到达一定次数之后，将错误消息记录日志，并发送预警信息

> 生产者客户端发送出去之后可能发生网络丢包、网络故障等造成消息丢失
> 生产者将信道设置成confirm模式。一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的id，一旦消息被投递到所有匹配的队列之后，RabbitMQ就会发送一个确认(Basic.ACK)
> 给生产者（包含消息的唯一id），这就使得生产者知晓消息已经正确到达目的地了。RabbitMQ回传给生产者的确认消息中的deliveryTag包含了确认消息的序号，此外RabbitMQ也可以设置
> channel.basicACK()中的multiple参数，表示这个序号之前的所有消息都已经得到了处理  
> 
> 客户端实现生产者confirm有三种方式  
> ① 普通confirm模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm。实际上是一种串行的confirm了  
> ② 批量confirm模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm  
> ③ 异步confirm模式：提供一个回调方法，服务端confirm了一条或者多条消息后client端会回调这个方法
> 
> ##### 消息发送失败补偿方案
> ![img.png](images/消息发送失败补偿方案.png)
> 当消息发送失败后，结合MQ配置，对消息进行重试并记录error日志，达到重试次数后，将处理结果通过回调接口的方式告诉生产者，生产者去进行额外的补偿机制

## 存储阶段
如果broker出现故障，仍然有可能出现消息丢失的。可以通过配置broker参数来避免因为宕机而丢失消息  
对于单个节点的broker，可以配置成在收到消息后，将消息写入磁盘后再给producer返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，恢复后还可以继续使用  
对于broker集群，需要将broker配置成至少将消息发送到2个以上的节点，再给客户端回复确认响应，这样broker宕机后，其他broker还可以代替其工作

### 消费阶段
手动确认机制

> 消息消费失败处理方案
> ① 设置死信队列：当消息发送失败后，设置requeue=false消息进入死信队列，并获取死信队列的长度，设置重新发送到正常队列的重试时间和重试间隔，
> 重新发送到正常队列。  
> ② 将消息存入本地客户端，进行重发：将消费失败的消息，存入redis或者持久化到消费端的数据库表  
> 总结：死信队列能很好 的处理消息消费失败的场景，使用MQ原生的支持，避免过重的设计，使用方案一即可

> 死信队列补偿机制
> ![img.png](images/死信队列补偿机制.png)
> 说明：当消息消费失败后，进入死信队列，运维同事监控死信队列，及时预警。当评估不是因为数据的原因导致消费失败，运维同事在管理平台手动将消息迁移到正常队列  
> 获取死信队列的长度，当大于0时并判断是否超过重试次数并达到重试间隔，当没有超过重试次数时，可以自动将消息从死信队列迁移到正常队列

# 重复消费
> 用幂等性解决重复消息问题

① 利用数据库的唯一约束实现幂等  
② 为更新的数据设置前置条件  
③ 记录并检查操作

# 消息防堆积方案
在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康 的持续运行  
消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的是，
在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（队列）数量，确保 Consumer 的实例数和分区数量是相等的

# 顺序消费
首先如果这个队列的消费者只有一个，那由于队列的先进先出的特性就能保证消息的顺序消费，此方案适用于数据量较小的情况，如果消息数量较少，
可以直接放在内存的队列结构中，比如list结构，然后在内存中排队，再去按照排队后的顺序执行就能保证消息消费的顺序性，根据关键值进行hash操作，
将关键值相同的数据放到内存队列中，然后在内部排序后，由一个线程去处理
如果这个队列有多个消费者，那么将队列拆分成多个，然后的操作就是把对相同id的更改放入同一个队列，这样就能保证对同一条数据的更新操作是有序的。

# RocketMQ事务消息解决分布式事务
由于传统的处理方式无法解决消息生产者本地事务处理成功与消息发送成功两者的一致性，因此事务消息就诞生了，它实现了消息生成者本地事务与消息发送的原子性，
保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题
![img.png](images/MQ消息最终一致性解决方案.png)

注意点：由于MQ通常都会保证消息能够投递成功，因此，如果业务没有及时返回ACK结果，那么就有可能造成MQ的重复消息投递问题。因此，
对于消息最终一致性的方案，消息的消费组必须要对消息的消费支持幂等，不能造成同一条消息的重复消费的情况

### 事务消息的异常情况分析
##### 如果预发送消息失败，是不是业务就不执行了？
对于基于消息最终一致性的方案，一般都会强依赖这步，如果这个步骤无法得到保证，那么也就不可能做到最终一致性了

##### 为什么要增加一个预发送机制，增加两次发布出去消息的重试机制，为什么不在业务成功之后，发送失败的话使用一次重试机制？
如果业务执行成功，再去发消息，此时如果还没来得及发消息，业务系统就已经宕机了，系统重启后，根本没有记录之前是否发送过消息，这样就会导致业务执行成功，消息最终没发出去的情况

##### 如果consumer消费失败，是否需要producer做回滚了？
这里的事务消息，producer并不会因为consumer消费失败而做回滚，采用事务消息的应用，其所追求的高可用和最终一致性，消息消费失败的话，MQ自己会负责重推消息，直到消费成功。因此，
事务消息是针对生产端而言的。对于消费端，消费端的一致性是通过MQ的重试机制来完成的

##### 如果consumer端因为业务异常而导致回滚，那么岂不是两边最终无法保证一致性？
基于消息的最终一致性方案必须保证消费端在业务上的操作没障碍，它只允许系统异常的失败，不允许业务上的失败，比如你在业务上跑出个NPE之类的问题，导致你消费端执行事务失败，那么就很难做到一致了
